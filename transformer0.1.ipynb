{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\xiao_work\\code\\NLP\\env2\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import PennTreebank as WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchdata.datapipes.iter import FileOpener, IterableWrapper\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 1320 batches | lr 5.00 | ms/batch 96.96 | loss  7.14 | ppl  1264.54\n",
      "| epoch   1 |   400/ 1320 batches | lr 5.00 | ms/batch 10.96 | loss  6.07 | ppl   433.87\n",
      "| epoch   1 |   600/ 1320 batches | lr 5.00 | ms/batch 10.99 | loss  5.84 | ppl   343.14\n",
      "| epoch   1 |   800/ 1320 batches | lr 5.00 | ms/batch 11.09 | loss  5.66 | ppl   288.57\n",
      "| epoch   1 |  1000/ 1320 batches | lr 5.00 | ms/batch 10.97 | loss  5.59 | ppl   267.34\n",
      "| epoch   1 |  1200/ 1320 batches | lr 5.00 | ms/batch 10.97 | loss  5.48 | ppl   238.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 32.25s | valid loss  5.48 | valid ppl   238.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 1320 batches | lr 4.75 | ms/batch 11.05 | loss  5.41 | ppl   224.04\n",
      "| epoch   2 |   400/ 1320 batches | lr 4.75 | ms/batch 10.98 | loss  5.35 | ppl   209.78\n",
      "| epoch   2 |   600/ 1320 batches | lr 4.75 | ms/batch 10.97 | loss  5.31 | ppl   202.85\n",
      "| epoch   2 |   800/ 1320 batches | lr 4.75 | ms/batch 10.99 | loss  5.25 | ppl   190.73\n",
      "| epoch   2 |  1000/ 1320 batches | lr 4.75 | ms/batch 11.01 | loss  5.26 | ppl   191.84\n",
      "| epoch   2 |  1200/ 1320 batches | lr 4.75 | ms/batch 11.02 | loss  5.17 | ppl   176.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 15.05s | valid loss  5.32 | valid ppl   204.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 1320 batches | lr 4.51 | ms/batch 11.09 | loss  5.17 | ppl   176.49\n",
      "| epoch   3 |   400/ 1320 batches | lr 4.51 | ms/batch 10.99 | loss  5.14 | ppl   170.44\n",
      "| epoch   3 |   600/ 1320 batches | lr 4.51 | ms/batch 11.01 | loss  5.12 | ppl   166.83\n",
      "| epoch   3 |   800/ 1320 batches | lr 4.51 | ms/batch 11.05 | loss  5.07 | ppl   159.68\n",
      "| epoch   3 |  1000/ 1320 batches | lr 4.51 | ms/batch 11.00 | loss  5.09 | ppl   162.57\n",
      "| epoch   3 |  1200/ 1320 batches | lr 4.51 | ms/batch 11.09 | loss  5.01 | ppl   149.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 15.10s | valid loss  5.27 | valid ppl   193.73\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.22 | test ppl   185.38\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            \n",
    "    return output,output_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,output_flat = test_model(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.5627,  8.4395,  9.5194,  ..., -0.7235, -0.7780, -0.8680],\n",
       "         [ 6.4535,  7.1811,  5.9501,  ...,  0.2007, -1.4373, -0.7319],\n",
       "         [ 6.7456,  6.0094,  4.6613,  ..., -0.3515, -0.8430, -0.9814],\n",
       "         ...,\n",
       "         [ 6.9886,  9.4980,  6.9543,  ..., -0.7978, -0.4228, -1.0340],\n",
       "         [ 6.3512,  9.9041,  6.8769,  ..., -1.2405, -1.1157, -0.8191],\n",
       "         [ 7.1915,  7.2453,  4.4525,  ..., -0.2293, -1.5100, -1.1561]],\n",
       "\n",
       "        [[ 7.5385,  9.1519,  6.9380,  ..., -0.6165, -1.3680, -1.1220],\n",
       "         [ 6.5797,  8.0680,  5.5419,  ..., -0.8307, -0.6318, -0.9180],\n",
       "         [ 6.2913,  5.8604,  6.4272,  ..., -1.3491, -1.1851, -1.6640],\n",
       "         ...,\n",
       "         [ 6.4427,  7.7032,  5.1773,  ..., -1.1556, -0.7085, -0.8116],\n",
       "         [ 6.3415,  7.8796,  5.0094,  ..., -1.2116, -0.7512, -0.8428],\n",
       "         [ 6.5868,  7.5897,  5.4035,  ..., -1.1388, -0.7526, -0.9251]],\n",
       "\n",
       "        [[ 6.8834,  4.2547,  6.2985,  ..., -1.0445, -1.5299, -1.4442],\n",
       "         [ 6.6689,  6.1079,  8.0761,  ..., -0.3626, -0.2319, -0.7205],\n",
       "         [ 6.1168,  8.5977,  4.9226,  ..., -1.4916, -1.3493, -0.9415],\n",
       "         ...,\n",
       "         [ 6.1634,  8.8149,  5.3974,  ..., -0.6883, -0.6644, -1.1232],\n",
       "         [ 5.9494,  7.5182,  4.9930,  ..., -1.1604, -0.9805, -0.8141],\n",
       "         [ 6.1630,  7.3313,  5.0930,  ..., -1.0778, -1.0113, -0.8408]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 6.1392,  8.1989,  7.2828,  ..., -0.4231, -0.3766, -1.0332],\n",
       "         [ 6.7614, 10.4980,  7.5829,  ..., -0.5556, -0.0702, -1.1849],\n",
       "         [ 5.7338,  7.6177,  4.7144,  ..., -1.4777, -1.5272, -0.8160],\n",
       "         ...,\n",
       "         [ 5.5257,  7.1123,  4.7592,  ..., -1.5243, -1.2506, -1.7724],\n",
       "         [ 6.0394,  5.0470,  4.7848,  ..., -1.0067, -1.2308, -0.1524],\n",
       "         [ 5.2525,  5.9793,  5.6719,  ..., -0.3853, -0.6528, -0.2620]],\n",
       "\n",
       "        [[ 6.1359,  9.2514,  7.8030,  ..., -1.1399, -1.1090, -1.2984],\n",
       "         [ 5.6832,  8.7880,  4.0552,  ..., -1.7386, -1.8162, -0.4307],\n",
       "         [ 6.7513,  7.7521,  6.0866,  ..., -1.3462, -0.9045, -0.6899],\n",
       "         ...,\n",
       "         [ 6.3873,  7.5677,  5.1177,  ..., -1.1708, -0.9230, -0.8241],\n",
       "         [ 6.3303,  7.7379,  4.8938,  ..., -1.2093, -0.7759, -0.8619],\n",
       "         [ 6.2686,  6.4406,  8.2797,  ..., -0.8546, -0.0539, -0.8262]],\n",
       "\n",
       "        [[ 5.6569,  5.5439,  7.3911,  ..., -1.2493, -0.9920, -0.4430],\n",
       "         [ 5.9064,  8.1142,  6.1638,  ..., -0.4316, -0.5520, -0.8695],\n",
       "         [ 6.5459,  9.5017,  5.7079,  ..., -0.7772, -0.4379, -0.9447],\n",
       "         ...,\n",
       "         [ 6.0034,  7.5710,  5.3905,  ..., -1.1777, -1.2061, -0.7920],\n",
       "         [ 6.9125,  9.8651,  5.1875,  ..., -1.1679, -1.3985, -0.4808],\n",
       "         [ 6.2579,  8.2160,  5.5562,  ..., -1.0192, -0.4076, -0.6889]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
